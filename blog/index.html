<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>
        blog | ICLR Blogposts 2025</title>
    <meta name="author" content="ICLR  Blog">
    <meta name="description" content="Home to the 2025 ICLR Blogposts track
">
    <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, iclr">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/iclr_favicon.ico">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://mjlee5982.github.io/blog/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">ICLR Blogposts 2025</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <!-- [#&lt;Jekyll::Page @relative_path=&quot;404.html&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;_pages/about.md&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;_pages/call.md&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;_pages/dropdown.md&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;index.md&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;assets/css/main.scss&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;_pages/reviewer_guidelines.md&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;robots.txt&quot;&gt;, #&lt;Jekyll::Page @relative_path=&quot;_pages/submitting.md&quot;&gt;, #&lt;Jekyll:Archive @type=year @title={:year=&gt;&quot;2024&quot;} @data={&quot;layout&quot;=&gt;&quot;archive-year&quot;}&gt;, #&lt;Jekyll:Archive @type=year @title={:year=&gt;&quot;2025&quot;} @data={&quot;layout&quot;=&gt;&quot;archive-year&quot;}&gt;, #&lt;JekyllRedirectFrom::PageWithoutAFile @relative_path=&quot;redirects.json&quot;&gt;, #&lt;JekyllFeed::PageWithoutAFile @relative_path=&quot;feed.xml&quot;&gt;, #&lt;Jekyll::PaginateV2::Generator::PaginationPage @relative_path=&quot;.html&quot;&gt;, #&lt;Jekyll::PageWithoutAFile @relative_path=&quot;sitemap.xml&quot;&gt;, #&lt;Jekyll::SourceMapPage @name=&quot;main.css.map&quot;&gt;] -->

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/2023/about">about</a>
              </li> -->
              <!-- Call -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/2023/call">call</a>
              </li> -->
              <!-- submissions -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/2023/submissions/">submissions</a>
              </li> -->
              <!-- Blog -->
              <!-- <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li> -->
              <!-- 2022 -->
              <!-- <li class="nav-item">
                <a class="nav-link" href="https://iclr-blog-track.github.io/home/">2022 edition <u>⤤</u><span class="sr-only">(current)</span></a>
              </li> -->

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/about/">about</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/call/">call for blogposts</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/submitting/">submitting</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/reviewing/">reviewing</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/blog/index.html">blog<span class="sr-only">(current)</span></a>
              </li>
                <li class="nav-item dropdown ">
                  <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a>
                  <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                    <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/" rel="external nofollow noopener noopener noreferrer" target="_blank"><strong>2025</strong></a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/" rel="external nofollow noopener noopener noreferrer" target="_blank">2024</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/" rel="external nofollow noopener noopener noreferrer" target="_blank">2023</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener noopener noreferrer" target="_blank">2022</a>
                  </div>
                </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <div class="header-background"><div class="img"></div></div>      

    <!-- Content -->
    <div class="container mt-5">
      <div class="post">

  <div class="header-bar">
    <h1>blogposts</h1>
    <h2>Blog Posts</h2>
  </div>

  

  <ul class="post-list">
    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/analytical-simulated-dynamics/">A primer on analytical learning dynamics of nonlinear neural networks</a>
        
      </h3>
      <p>The learning dynamics of neural networks—in particular, how parameters change over time during training—describe how data, architecture, and algorithm interact in time to produce a trained neural network model. Characterizing these dynamics, in general, remains an open problem in machine learning, but, handily, restricting the setting allows careful empirical studies and even analytical results. In this blog post, we review approaches to analyzing the learning dynamics of nonlinear neural networks, focusing on a particular setting known as teacher-student that permits an explicit analytical expression for the generalization error of a nonlinear neural network trained with online gradient descent. We provide an accessible mathematical formulation of this analysis and a JAX codebase to implement simulation of the analytical system of ordinary differential equations alongside neural network training in this setting. We conclude with a discussion of how this analytical paradigm has been used to investigate generalization in neural networks and beyond.</p>
      <p class="post-meta">
        32 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/conditional-flow-matching/">A Visual Dive into Conditional Flow Matching</a>
        
      </h3>
      <p>Conditional flow matching (CFM) was introduced by three simultaneous papers at ICLR 2023, through different approaches (conditional matching, rectifying flows and stochastic interpolants). <br> The main part of this post, Section 2, explains CFM by using both visual intuitions and insights on its probabilistic formulations. Section 1 introduces nomalizing flows; it can be skipped by reader familiar with the topic, or that wants to cover them later. Section 3 opens on the links between CFM and other approaches, and ends with a 'CFM playground'.</p>
      <p class="post-meta">
        44 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/sparse-autodiff/">An Illustrated Guide to Automatic Sparse Differentiation</a>
        
      </h3>
      <p>In numerous applications of machine learning, Hessians and Jacobians exhibit sparsity, a property that can be leveraged to vastly accelerate their computation. While the usage of automatic differentiation in machine learning is ubiquitous, automatic sparse differentiation (ASD) remains largely unknown. This post introduces ASD, explaining its key components and their roles in the computation of both sparse Jacobians and Hessians. We conclude with a practical demonstration showcasing the performance benefits of ASD.</p>
      <p class="post-meta">
        46 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/analysing-the-spectral-biases-in-generative-models/">Analysing The Spectral Biases in Generative Models</a>
        
      </h3>
      <p>Diffusion and GAN models have demonstrated remarkable success in synthesizing high-quality images propelling them into various real-life applications across different domains. However, it has been observed that they exhibit spectral biases that impact their ability to generate certain frequencies and makes it possible to distinguish real images from fake ones. In this blog we analyze these models and attempt to explain the reason behind these biases.</p>
      <p class="post-meta">
        30 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/opt-summary/">Avoid Overclaims - Summary of Complexity Bounds for Algorithms in Minimization and Minimax Optimization</a>
        
      </h3>
      <p>In this blog, we revisit the convergence analysis of first-order algorithms in minimization and minimax optimization problems. Within the classical oracle model framework, we review the state-of-the-art upper and lower bound results in various settings, aiming to identify gaps in existing research. With the rapid development of applications like machine learning and operation research, we further identify some recent works that revised the classical settings of optimization algorithms study.</p>
      <p class="post-meta">
        36 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/building-blocks-of-differentially-private-training/">Building Blocks of Differentially Private Training</a>
        
      </h3>
      <p>In this blog, we introduce the building blocks of training a neural network in a differentially private way.</p>
      <p class="post-meta">
        43 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/rethinking-llm-simulation/">Can LLM Simulations Truly Reflect Humanity? A Deep Dive</a>
        
      </h3>
      <p>Simulation powered by Large Language Models (LLMs) has become a promising method for exploring complex human social behaviors. However, the application of LLMs in simulations presents significant challenges, particularly regarding their capacity to accurately replicate the complexities of human behaviors and societal dynamics, as evidenced by recent studies highlighting discrepancies between simulated and real-world interactions. This blog rethinks LLM-based simulations by emphasizing both their limitations and the necessities for advancing LLM simulations. By critically examining these challenges, we aim to offer actionable insights and strategies for enhancing the applicability of LLM simulations in human society in the future.</p>
      <p class="post-meta">
        21 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/pessa/">Cross-Layer Orthogonal Vectors Pruning and Fine-Tuning</a>
        
      </h3>
      <p>The absorb operation utilized in DeepSeek, which merges Query-Key and Value-Output weight matrices during inference, significantly increases parameter count and computational overhead. We observe that these absorbed matrices inherently exhibit low-rank structures. Motivated by this insight, we introduce CLOVER (Cross-Layer Orthogonal Vectors), a method that factorizes these matrices into four head-wise orthogonal matrices and two sets of singular values without any loss of information. By eliminating redundant vectors, CLOVER reduces the encoder parameters in Whisper-large-v3 by 46.42% without requiring additional training. Moreover, by freezing singular vectors and fine-tuning only singular values, CLOVER enables efficient full-rank fine-tuning. When evaluated on eight commonsense reasoning tasks with LLaMA-2 7B, CLOVER surpasses existing SoTA methods—LoRA, DoRA, HiRA, and PiSSA—by 7.6%, 5.5%, 3.8%, and 0.7%, respectively.</p>
      <p class="post-meta">
        35 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/do-not-write-jailbreak-papers/">Do not write that jailbreak paper</a>
        
      </h3>
      <p>Jailbreaks are becoming a new ImageNet competition instead of helping us better understand LLM security. The community should revisit their choices and focus on research that can uncover new security vulnerabilities.</p>
      <p class="post-meta">
        12 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/toddlers-vs-vismodels/">Do vision models perceive objects like toddlers ?</a>
        
      </h3>
      <p>Despite recent advances in artificial vision systems, humans are still more data-efficient at learning strong visual representations. Psychophysical experiments suggest that toddlers develop fundamental visual properties between the ages of one and three, which affect their perceptual system for the rest of their life. They begin to recognize impoverished variants of daily objects, pay more attention to the shape of an object to categorize it, prefer objects in specific orientations and progressively generalize over the configural arrangement of objects' parts. This post examines whether these four visual properties also emerge in off-the-shelf machine learning (ML) vision models. We reproduce and complement previous studies by comparing toddlers and a large set of diverse pre-trained vision models for each visual property. This way, we unveil the interplay between these visual properties and highlight the main differences between ML models and toddlers. Code is available at (https://github. com/Aubret/BabyML).</p>
      <p class="post-meta">
        30 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/localization/">Does Editing Provide Evidence for Localization?</a>
        
      </h3>
      <p>A basic aspiration for interpretability research in large language models is to localize semantically meaningful behaviors to particular components within the LLM. There are various heuristics for finding candidate locations within the LLM. Once a candidate localization is found, it can be assessed by editing the internal representations at the corresponding localization and checking whether this induces model behavior that is consistent with the semantic interpretion of the localization. The question we address here is, how strong is the evidence provided by such edits? To assess localization, we want to assess the effect of the optimal intervention at a particular location. The key new technical tool is a way of adapting LLM alignment techniques to find such optimal localized edits. With this tool in hand, we give an example where the edit-based evidence for localization appears strong, but where localization clearly fails. Indeed, we find that optimal edits at random localizations can be as effective as aligning the full model. In aggregate, our results suggest that merely observing that localized edits induce targeted changes in behavior provides little to no evidence that these locations actually encode the target behavior.</p>
      <p class="post-meta">
        26 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/factual-validation-simplification/">Factual Context Validation and Simplification: A Scalable Method to Enhance GPT Trustworthiness and Efficiency</a>
        
      </h3>
      <p>As the deployment of Large Language Models (LLMs) like GPT expands across domains, mitigating their susceptibility to factual inaccuracies or hallucinations becomes crucial for ensuring reliable performance. This blog post introduces two novel frameworks that enhance retrieval-augmented generation (RAG): one uses summarization to achieve a maximum of 57.7% storage reduction, while the other preserves critical information through statement-level extraction. Leveraging DBSCAN clustering, vectorized fact storage, and LLM-driven fact-checking, the pipelines deliver higher overall performance across benchmarks such as PubMedQA, SQuAD, and HotpotQA. By optimizing efficiency and accuracy, these frameworks advance trustworthy AI for impactful real-world applications.</p>
      <p class="post-meta">
        31 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/fine-tuning-token-based-large-multimodal-models/">Fine-Tuning Token-Based Large Multimodal Models: What Works, What Doesn’t and What's Next</a>
        
      </h3>
      <p>In this blog post, we explore the advancements and challenges in fine-tuning unified token-based large multimodal models, focusing on the Chameleon architecture and its fine-tuned variant, Anole. Released in 2024, these models exemplify a modern approach for integrating various data modalities through tokens, simplifying modal fusion and leveraging established techniques from large language models. The post details our research efforts to reveal what is important, what is mistaken, and what is worth exploring in future research during the fine-tuning process.</p>
      <p class="post-meta">
        32 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/imagenet-flaws/">Flaws of ImageNet, Computer Vision's Favorite Dataset</a>
        
      </h3>
      <p>Since its release, ImageNet-1k has been a gold standard for evaluating model performance. It has served as the foundation of numerous other datasets and it has been widely used for pretraining. <br> As models have improved, issues related to label correctness have become increasingly apparent. In this blog post, we analyze the issues, including incorrect labels, overlapping or ambiguous class definitions, training-evaluation domain shifts, and image duplicates. The solutions for some problems are straightforward. For others, we hope to start a broader conversation about how to improve this influential dataset to better serve future research.</p>
      <p class="post-meta">
        57 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/flow-with-what-you-know/">Flow With What You Know</a>
        
      </h3>
      <p>This tutorial provides an accessible introduction to flow-matching and rectified flow models, which are increasingly at the forefront of generative AI applications. Typical descriptions of them are often laden with extensive probability-math equations, which can form barriers to the dissemination and understanding of these models. Fortunately, before they were couched in probabilities, the mechanisms underlying these models were grounded in basic physics, which provides an alternative and highly accessible (yet functionally equivalent) representation of the processes involved.</p>
      <p class="post-meta">
        82 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/interpret-classification/">How do we interpret the outputs of a neural network trained on classification?</a>
        
      </h3>
      <p>This post shows how neural networks trained for classification approximate the Bayesian posterior, explaining the theoretical basis and providing empirical examples.</p>
      <p class="post-meta">
        21 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/visualizing-training/">How to visualize training dynamics in neural networks</a>
        
      </h3>
      <p>Deep learning practitioners typically rely on training and validation loss curves to understand neural network training dynamics. This blog post demonstrates how classical data analysis tools like PCA and hidden Markov models can reveal how neural networks learn different data subsets and identify distinct training phases. We show that traditional statistical methods remain valuable for understanding the training dynamics of modern deep learning systems.</p>
      <p class="post-meta">
        11 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/engram/">In Search of the Engram in LLMs: A Neuroscience Perspective on the Memory Functions in AI Models</a>
        
      </h3>
      <p>Large Language Models (LLMs) are enhancing our daily lives but also pose risks like spreading misinformation and violating privacy, highlighting the importance of understanding how they process and store information. This blogpost offers a fresh look into a neuroscience-inspired perspective of LLM's memory functions, based on the concept of engrams-the physical substrate of memory in living organism. We discuss a synergy between AI research and neuroscience, as both fields cover complexities of intelligent systems.</p>
      <p class="post-meta">
        18 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/feature-geometry/">Intricacies of Feature Geometry in Large Language Models</a>
        
      </h3>
      <p>Studying the geometry of a language model's embedding space is an important and challenging task because of the various ways concepts can be represented, extracted, and used. Specifically, we want a framework that unifies both measurement (of how well a latent explains a feature/concept) and causal intervention (how well it can be used to control/steer the model). We discuss several challenges with using some recent approaches to study the geometry of categorical and hierarchical concepts in large language models (LLMs) and both theoretically and empirically justify our main takeaway, which is that their orthogonality and polytopes results are trivially true in high-dimensional spaces, and can be observed even in settings where they should not occur.</p>
      <p class="post-meta">
        25 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/linrec/">Linear Recurrences Accessible to Everyone</a>
        
      </h3>
      <p>Investigating linear RNNs such as Mamba, can be challenging because they are currently not efficiently expressible in PyTorch. We propose the abstraction of linear recurrences to gain intuition for the computational structure of these emerging deep learning architectures. After deriving their parallel algorithm, we gradually build towards a simple template CUDA extension for PyTorch. We hope that making linear recurrences accessible to a wider audience inspires further research on linear-time sequence mixing.</p>
      <p class="post-meta">
        59 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/llm-democracy/">LLMs' Potential Influences on Our Democracy: Challenges and Opportunities</a>
        
      </h3>
      <p>With growing research and attention on LLMs' potential influence on political discourse and democratic processes, this blog post discusses the path forward and proposes future research questions in four broad areas: (1) evaluation of LLM political leanings, (2) understanding LLMs' influence on our democracy, (3) better policy frameworks for AI development, and (4) technical solutions to adjust or mitigate political leanings. As LLMs become increasingly integrated into society, continued investigation of how they will reshape democracy is essential to maximize their benefits while minimizing risks to democratic processes.</p>
      <p class="post-meta">
        12 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/lost-in-prediction/">Lost in Prediction: Why Social Media Narratives Don't Help Macroeconomic Forecasting?</a>
        
      </h3>
      <p>Can we predict the macroeconomy by analyzing the narratives people share on social media? We dove deep into the world of Narrative Economics, using NLP models to analyze millions of viral tweets and see if they could help us predict the fluctuations of macroeconomic indicators. 🚨 Spoiler alert: it's not that easy!  Join us as we explore the interesting relationship between narratives, social media, and macroeconomy, and uncover the challenges of turning narratives into treasure.</p>
      <p class="post-meta">
        26 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/vlm-understanding/">Mechanistic Interpretability Meets Vision Language Models: Insights and Limitations</a>
        
      </h3>
      <p>Vision language models (VLMs), such as GPT-4o, have rapidly evolved, demonstrating impressive capabilities across diverse tasks. However, much of the progress in this field has been driven by engineering efforts, with a limited understanding of how these models work. The lack of scientific insight poses challenges to further enhancing their robustness, generalization, and interpretability, especially in high-stakes settings. In this work, we systematically review the use of mechanistic interpretability methods to foster a more scientific and transparent understanding of VLMs. Specifically, we examine five prominent techniques: probing, activation patching, logit lens, sparse autoencoders, and automated explanation. We summarize the key insights these methods provide into how VLMs process information and make decisions. We also discuss critical challenges and limitations that must be addressed to further advance the field.</p>
      <p class="post-meta">
        29 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/ebm-vs-mcmc/">Models trained with unnormalized density functions: A need for a course correction</a>
        
      </h3>
      <p>Training a generative model with energy or unnormalized density functions is considered an important problem for physical systems such as molecules. This provides a path to train generative models to sample from the much desired Boltzmann distribution in situations of data scarcity. As of late, several generative frameworks have been proposed to target this problem. However, as we show in the following blog post, these methods have not been benchmarked sufficiently well against traditional Markov Chain Monte Carlo (MCMC) methods that are used to sample from energy functions. We take the example of two recent methods (iDEM and iEFM) and show that MCMC outperforms both methods in terms of number of energy evaluations and wall clock time on established baselines. With this, we suggest a “course correction” on the benchmarking of these models and comment on the utility and potential of generative models on these tasks.</p>
      <p class="post-meta">
        41 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/mad/">Multi-LLM-Agents Debate - Performance, Efficiency, and Scaling Challenges</a>
        
      </h3>
      <p>Multi-Agent Debate (MAD) explores leveraging collaboration among multiple large language model (LLM) agents to improve test-time performance without additional training. This blog evaluates five MAD frameworks across nine benchmarks, revealing that current MAD methods fail to consistently outperform simpler single-agent strategies, even with increased computational resources. Analysis of factors such as agent configurations and debate rounds suggests that existing MAD designs fall short in fully utilizing additional inference-time computation.</p>
      <p class="post-meta">
        20 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/multimodal-learning/">Multi-modal Learning: A Look Back and the Road Ahead</a>
        
      </h3>
      <p>Advancements in language models has spurred an increasing interest in multi-modal AI — models that process and understand information across multiple forms of data, such as text, images and audio. While the goal is to emulate human-like ability to handle diverse information, a key question is: do human-defined modalities align with machine perception? If not, how does this misalignment affect AI performance? In this blog, we examine these questions by reflecting on the progress made by the community in developing multi-modal benchmarks and architectures, highlighting their limitations. By reevaluating our definitions and assumptions, we propose ways to better handle multi-modal data by building models that analyze and combine modality contributions both independently and jointly with other modalities.</p>
      <p class="post-meta">
        17 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/llm-knowledge-distil/">On LLM Knowledge Distillation - A Comparison between Forward KL and Reverse KL</a>
        
      </h3>
      <p>In this blog post, we delve into knowledge distillation techniques for Large Language Models (LLMs), with a particular focus on using Kullback-Leibler (KL) Divergence as the optimization objective. Knowledge distillation is a powerful tool to reduce model size while maintaining comparable performance, making it especially useful in scenarios with constrained computational or serving resources. We specifically explore the nuances of Forward KL divergence and Reverse KL divergence, examining their roles in the distillation process. By comparing these two approaches, we aim to uncover their behaviours, strengths, and practical applications in LLM distillation.</p>
      <p class="post-meta">
        24 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/fisher/">On the Computation of the Fisher Information in Continual Learning</a>
        
      </h3>
      <p>One of the most popular methods for continual learning with deep neural networks is Elastic Weight Consolidation (EWC), which involves computing the Fisher Information. The exact way in which the Fisher Information is computed is however rarely described, and multiple different implementations for it can be found online. This blog post discusses and empirically compares several often-used implementations, which highlights that many currently reported results for EWC could likely be improved by changing the way the Fisher Information is computed.</p>
      <p class="post-meta">
        18 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/llm-context-utilization/">Open-Source vs Close-Source: The Context Utilization Challenge</a>
        
      </h3>
      <p>This blog post aims to evaluate how well the most capable open-source long context large language models (LLMs) utilize context, using the Needle In A Haystack test. We adopt the task of chapter summarization for recently published books to minimize data contamination while ensuring a challenging test. Our results show that open-source models still have room to improve in context utilization compared to close-source models.</p>
      <p class="post-meta">
        21 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/risks-private-evals/">Peeking Behind Closed Doors: Risks of LLM Evaluation by Private Data Curators</a>
        
      </h3>
      <p>A critical examination of the risks and challenges posed by private evaluators (for example ScaleAI) in the LLM landscape, highlighting financial incentives, conflicts of interest, and prevalence of evaluation biases even when acting in good faith.</p>
      <p class="post-meta">
        17 min read   ·  
        November 22, 2024
      </p>
      <p class="post-tags">
        <a href="/blog/2024">
          <i class="fas fa-calendar fa-sm"></i> 2024 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/pitfalls-of-evidence-based-ai-policy/">Pitfalls of Evidence-Based AI Policy</a>
        
      </h3>
      <p>Evidence is of irreplaceable value to policymaking. However, there are systematic biases shaping the evidence that the AI community produces. Holding regulation to too high an evidentiary standard can lead to systmatic neglect of certain risks. If the goal is evidence-based AI policy, the first regulatory objective must be to actively facilitate the process of identifying, studying, and deliberating about AI risks.</p>
      <p class="post-meta">
        37 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/positional-embedding/">Positional Embeddings in Transformer Models: Evolution from Text to Vision Domains</a>
        
      </h3>
      <p>Positional encoding has become an essential element in transformer models, addressing their fundamental property of permutation invariance and allowing them to understand sequential relationships within data. This blog post examines positional encoding techniques, emphasizing their vital importance in traditional transformers and their use with 2D data in Vision Transformers (ViT). We explore two contemporary methods—ALiBi (Attention with Linear Biases) and RoPE (Rotary Position Embedding)—analyzing their unique approaches to tackling the challenge of sequence length extrapolation during inference, a significant issue for transformers. Additionally, we compare these methods' fundamental similarities and differences, assessing their impact on transformer performance across various fields. We also look into how interpolation strategies have been utilized to enhance the extrapolation capabilities of these methods; we conclude this blog with an empirical comparison of ALiBi and RoPE in Vision Transformers. To the best of our knowledge, this represents the first direct comparison of these positional encoding methods with those used in standard Vision Transformers.</p>
      <p class="post-meta">
        32 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/foundation-adapter/">Pre-training of Foundation Adapters for LLM Fine-tuning</a>
        
      </h3>
      <p>Adapter-based fine-tuning methods insert small, trainable adapters into frozen pre-trained LLMs, significantly reducing computational costs while maintaining performance. However, despite these advantages, traditional adapter fine-tuning suffers from training instability due to random weight initialization. This instability can lead to inconsistent performance across different runs.  Therefore, to address this issue, this blog post introduces pre-trained foundation adapters as a technique for weight initialization. This technique potentially improves the efficiency and effectiveness of the fine-tuning process. Specifically, we combine continual pre-training and knowledge distillation to pre-train foundation adapters. Experiments confirm the effectiveness of this approach across multiple tasks. Moreover, we highlight the advantage of using pre-trained foundation adapter weights over random initialization specifically in a summarization task.</p>
      <p class="post-meta">
        9 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/calibrated-mia/">Reassessing EMNLP 2024’s Best Paper: Does Divergence-Based Calibration for Membership Inference Attacks Hold Up?</a>
        
      </h3>
      <p><strong>TL;DR: No.</strong><br> A critical analysis of the EMNLP Best Paper proposing a divergence-based calibration for Membership Inference Attacks (MIAs). We explore its experimental shortcomings, issues with temporally shifted benchmarks, and what this means for machine learning awards.</p>
      <p class="post-meta">
        11 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/reexamining-the-aleatoric-and-epistemic-uncertainty-dichotomy/">Reexamining the Aleatoric and Epistemic Uncertainty Dichotomy</a>
        
      </h3>
      <p>When discussing uncertainty estimates for the safe deployment of AI agents in the real world, the field typically distinguishes between aleatoric and epistemic uncertainty. This dichotomy may seem intuitive and well-defined at first glance, but this blog post reviews examples, quantitative findings, and theoretical arguments that reveal that popular definitions of aleatoric and epistemic uncertainties directly contradict each other and are intertwined in fine nuances. We peek beyond the epistemic and aleatoric uncertainty dichotomy and reveal a spectrum of uncertainties that help solve practical tasks especially in the age of large language models.</p>
      <p class="post-meta">
        23 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/repurposing/">Repurposing in AI: A Distinct Approach or an Extension of Creative Problem Solving?</a>
        
      </h3>
      <p>Creativity is defined as the ability to produce novel, useful, and surprising ideas. A sub area of creativity is creative problem solving, the capacity of an agent to discover novel and previously unseen ways to accomplish a task, according to its perspective. However, there is a related concept, repurposing, that has often been overlooked in the broader context of creative problem solving in AI. Repurposing involves identifying and utilizing existing objects, resources, or processes in innovative ways to address different problems. While these two concepts may seem distinct at first glance, recent studies in creativity in AI suggest that they may be more closely intertwined than previously thought. By examining the underlying mechanisms and cognitive processes involved in both creative problem solving and repurposing, we can begin to understand how these approaches complement each other.</p>
      <p class="post-meta">
        23 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/linear-gnn-convergence-restated/">Restating the Proof of Linear Convergence for Linear GNNs</a>
        
      </h3>
      <p>We lead the readers through the core proof of a pioneering paper that studies the training dynamics of linear GNNs. First, we reorganize the proof and provide a more concise and reader-friendly version, highlighting several key components. In doing so, we identify a hidden error and correct it, demonstrating that it has no impact on the main result. Additionally, we offer a dialectical discussion on the strengths and an overlooked aspect of the approach.</p>
      <p class="post-meta">
        24 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/rethinking-graph-prompts/">Rethinking Graph Prompts: Unraveling the Power of Data Manipulation in Graph Neural Networks</a>
        
      </h3>
      <p>Graph Neural Networks (GNNs) have transformed graph learning but face challenges like distribution shifts, data anomalies, and adversarial vulnerabilities. Graph prompt emerges as a novel solution, enabling data transformation to align graph data with pre-trained models without altering model parameters. This paradigm addresses negative transfer, enhances adaptability, and bridges modality gaps. Unlike traditional fine-tuning, graph prompts rewrite graph structures and features through components like prompt tokens and insertion patterns, improving flexibility and efficiency. Applications in IoT, drug discovery, fraud detection, and personalized learning demonstrate their potential to dynamically adapt graph data. While promising, challenges such as optimal design, benchmarks, and gradient issues persist. Addressing these will unlock  full potential of graph prompt to advance GNNs for complex real-world tasks.</p>
      <p class="post-meta">
        31 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/rethinking-quantization-for-the-real-world/">Rethinking Quantization for the Real World</a>
        
      </h3>
      <p>This blog post highlights the fact that most existing quantization techniques have been developed and validated under clean, balanced benchmark settings. It critically examines whether these methods can be reliably applied in real-world environments, where data imbalance and custom evaluation metrics constraints are the norm. Furthermore, it proposes ideas for partially mitigating the impact of real-world data imbalance during the Mixed Precision Quantization (MPQ) process.</p>
      <p class="post-meta">
        17 min read   ·  
        May 30, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/spd/">SPD Attack - Prevention of AI Powered Image Editing by Image Immunization</a>
        
      </h3>
      <p>Recent advances in image-to-image editing models offer both benefits and risks. While they enhance creativity, accessibility, and applications in fields ranging from medicine to environmental science, they can also enable misuse, such as identity manipulation, copyright infringement, and deepfake creation. This blog explores methods to protect images from such misuse, reproduces findings from relevant research, and extends them across various models and datasets.</p>
      <p class="post-meta">
        23 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/steering-llms-behavior/">Steering LLMs' Behavior with Concept Activation Vectors</a>
        
      </h3>
      <p>Concept activation vectors have been shown to take effects in safety concepts, efficiently and effectively guiding a considerable number of open-source large language models (LLMs) to respond positively to malicious instructions. In this blog, we aim to explore the capability boundaries of concept activation vectors in guiding various behaviors of LLMs through more extensive experiments. Our experiments show that this technique can transfer the text style at a low cost, but it is powerless to deal with short factual knowledge.</p>
      <p class="post-meta">
        21 min read   ·  
        May 7, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/the-illustrated-alphafold/">The Illustrated AlphaFold</a>
        
      </h3>
      <p>We present the Illustrated AlphaFold, a visual walkthrough of the architecture and information flow of AlphaFold 3. We explain every model component and training detail, with particular focus on the advances since AlphaFold 2 – including the unified tokenization scheme that extends to DNA, RNA, and small molecules, as well as the novel diffusion-based structural module. Finally, we include some musings on the ML lessons learned from studying AlphaFold 3.</p>
      <p class="post-meta">
        73 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/the-lottery-llm-hyperthesis/">The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?</a>
        
      </h3>
      <p>Motivated by reducing the computational and storage costs of LLMs, model compression and KV cache compression have attracted much attention from researchers. However, current methods predominantly emphasize maintaining the performance of compressed LLMs, as measured by perplexity or simple accuracy on tasks of common sense knowledge QA and basic arithmetic reasoning. In this blog, we present a brief review of recent advancements in LLMs related to retrieval-augmented generation, multi-step reasoning, external tools, and computational expressivity, all of which substantially enhance LLM performance. Then, we propose a lottery LLM hypothesis suggesting that for a given LLM and task, there exists a smaller lottery LLM capable of producing the same performance as the original LLM with the assistance of multi-step reasoning and external tools. Based on the review of current progress in LLMs, we discuss and summarize the essential capabilities that the lottery LLM and KV cache compression must possess, which are currently overlooked in existing methods.</p>
      <p class="post-meta">
        24 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/towards-more-rigorous-llm-evals/">Towards more rigorous evaluations of language models</a>
        
      </h3>
      <p>As language models (LMs) become increasingly sophisticated and existing benchmarks approach saturation, the need for rigorous evaluation methods grows more pressing. Many evaluations lack the statistical rigour needed to draw meaningful conclusions, leading to a potential over-confidence in results that might not hold up under scrutiny or replication. This post advocates for bringing fundamental statistical principles to language model evaluation, demonstrating how basic statistical analysis can provide more reliable insights into model capabilities and limitations. We show how to conduct this type of analysis using a recent paper as a case study. We hope this post serves as a tutorial for LM researchers aiming to enhance the rigor of their empirical evaluations.</p>
      <p class="post-meta">
        52 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/scalable-mcts/">Understanding Methods for Scalable MCTS</a>
        
      </h3>
      <p>Monte Carlo Tree Search (MCTS) is a versatile algorithm widely used for intelligent decision-making in complex, high-dimensional environments. While MCTS inherently improves with more compute, real-world applications often demand rapid decision-making under strict inference-time constraints. This blog post explores scalable parallelization strategies for MCTS, covering classical methods (leaf, root, and tree parallelism) and advanced distributed approaches—including virtual loss, transposition-driven scheduling, and distributed depth-first scheduling. By examining the practical trade-offs and performance implications of each method, we identify effective techniques for achieving high-throughput, low-latency planning—critical for applications like autonomous vehicles, emergency response systems, and real-time trading.</p>
      <p class="post-meta">
        27 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/calibration/">Understanding Model Calibration - A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)</a>
        
      </h3>
      <p>To be considered reliable, a model must be calibrated so that its confidence in each decision closely reflects its true outcome. In this blogpost we'll take a look at the most commonly used definition for calibration and then dive into a frequently used evaluation measure for model calibration. We'll then cover some of the drawbacks of this measure and how these surfaced the need for additional notions of calibration, which require their own new evaluation measures. This post is not intended to be an in-depth dissection of all works on calibration, nor does it focus on how to calibrate models. Instead, it is meant to provide a gentle introduction to the different notions and their evaluation measures as well as to re-highlight some  issues with a measure that is still widely used to evaluate calibration.</p>
      <p class="post-meta">
        24 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/pocp/">Why RoPE Struggles to Maintain Long-Term Decay in Long Sequences?</a>
        
      </h3>
      <p>Rotary Position Embedding (RoPE) improves upon traditional positional encodings but struggles with long-term decay in contexts exceeding its training length, limiting the model's generalization to longer sequences. Our experiments suggest that this issue may stem from a high proportion of obtuse angles on the complex plane between the linear transformations of query and key embeddings.</p>
      <p class="post-meta">
        21 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    

    
    
    
    

    <li>
      <h3>
        
          <a class="post-title" href="/blog/anthropomorphic-ai/">“I Am the One and Only, Your Cyber BFF”: Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI</a>
        
      </h3>
      <p>State-of-the-art generative AI (GenAI) systems are increasingly prone to anthropomorphic behaviors, i.e., to generating outputs that are perceived to be human-like. While this has led to scholars increasingly raising concerns about possible negative impacts such anthropomorphic AI systems can give rise to, anthropomorphism in AI development, deployment, and use remains vastly overlooked, understudied, and under-specified. In this blog post, we argue that we cannot thoroughly understand the impact of generative AI without understanding the impact of anthropomorphic AI, and outline a call to action.</p>
      <p class="post-meta">
        16 min read   ·  
        April 28, 2025
      </p>
      <p class="post-tags">
        <a href="/blog/2025">
          <i class="fas fa-calendar fa-sm"></i> 2025 </a>

          

          
    </p>
    </li>

    
  </ul>

  

</div>

    </div>

    <!-- Footer -->
    <!--    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        &copy; Copyright 2025 ICLR  Blog. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

      </div>
    </footer> -->

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
